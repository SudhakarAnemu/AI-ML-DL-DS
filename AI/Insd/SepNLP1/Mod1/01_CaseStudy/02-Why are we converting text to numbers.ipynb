{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_Why+are+we+converting+text+to+numbers.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NbiO44IXcLT3"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"360\" height=\"160\" /></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5dzA4Yt7Y7RP"},"source":["## What is Text?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bv3Qbd2RcfMQ"},"source":["- Text is a sequence of :\n"," - Characters\n"," - Words\n"," - Phrases and named entities\n"," - Sentences\n"," - Paragraphs..."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y06_T5FG_X1S"},"source":["## Can text be input in deep learning?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mn4sCMttBVBc"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/no3.JPG\" height = \"200\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lyOkLKCU_7FJ"},"source":[" - In order for machine to be **able to deal** with text data , the **text data** needs to be coverted to **numbers**.\n"," \n"," <center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/23456.JPG\" height = \"200\"/></center>\n"," \n"," - Then, it is fed into the **Machine Learning** and **Deep Learning Algorithms** for analysis."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-owAzujNR_6j"},"source":["<center><img src = \" https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/mrbean2.JPG\" height = \"300\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NXD7SMoPUs8s"},"source":["## For Example :\n","\n","- Lets consider two sentences and apply encoding.\n","\n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/Lovehate2.JPG\" height = \"150\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WIYLnOGcWqNA"},"source":["## Lets apply one of the popular encoding:  \n","**One - hot encoding** -  Converting text to vectors.\n","\n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/hatelove.JPG\" height = \"150\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VlOaR-Kfpcpf"},"source":["### We can expand this approach to any number of words by simply adding a new dimension for each new word in our vocabulary."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ekBqfX2tEMHC"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/problem.JPG\" height = \"200\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TOU3qhRJBv08"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/bvhfd.JPG\" height = \"400\" width = \"600\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HGscyGv3Z6ts"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/1183199.png\" height = \"200\"/></center>\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ircof9jdEwt8"},"source":["## So,  we use  Word Embedding \n","**Embedding** -  a **dense vecto**r with **similarity**.\n","-  It refers to something that's been **translated** into a vector.\n","-  Once we've created an **embedding**, we can **locate this vector** in something called a **vector space**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yf7r9l9YvDs7"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/dense.JPG\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J41XUG23p_mz"},"source":["## Why word vectors or word embedding?\n","\n","- Computer cannot do **computations** on strings.\n","\n","- Strings don’t hold much **explicit information** themselves.\n","\n","- Words Vectors are usually **dense vector representations**."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FhFVwCrXuAPs"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/explicit.JPG\" height = \"350\" width = \"800\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zBvF1vsGt3dA"},"source":["## VisualizingWord Embeddings"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DLEK5mV5Th8Z"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/manwoman.JPG\" height = \"300\"/></center>\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jBWEJj2NZCsE"},"source":["## For example:\n","- Let’s take the words **woman, man, queen, and king**.\n","- We can easily discern that there is some connection between these words. \n","- **“King”** and **“Queen”** are both **royal terms**. \n","- **“Man”** and **“Woman”** are **gender terms**.\n","-  But there is also a relationship between these pairs of terms.\n","-  A **“King”** is traditionally associated with the word **“Man”**.\n","-  A **“Queen”** is often associated with the word **“Woman.\"** \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7AOiB3LNMn_5"},"source":["<center><img src = \" https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/king.JPG\" height = \"300\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ToNZtlaHGj0C"},"source":["##   We can get their vector representations.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YHVWsyUrbyok"},"source":["-  **Vector** - It is just a set of real numbers.\n","- **Vector spaces** help us identify **similar patterns** more easily\n","-  For Example: \n","  - Red = [-1.4,-1.2]\n","   - Blue = [3,3]\n","   - Green = [3.2,2.9]\n","   - Yellow = [3.3,3.1]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"etfTVwSyXehV"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/tor%20spaces.png\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EOIIr219bTkn"},"source":["<center><img src = \" https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/vecs.png\" height = \"300\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TK92G5uhbuz6"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/roger.JPG\" height = \"200\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TAR5q0xyGApM"},"source":["## Word2Vec is word embedding.\n","- **Similarity** comes from **neighbour words**."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_qvWzScqQ_Io"},"source":["<center><img src =\"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/wejnv.JPG\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oeKO-rhKGKST"},"source":["## Lets consider two sentences"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l4Hw7IdnHLdI"},"source":["<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/brave.JPG\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-zCzNpDmHleJ"},"source":["## Neighbours with window size = 1:\n","<center><img src = \"https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/brave2.JPG\"/></center>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jwB-o7uGKwRn"},"source":["## Neighbours with window size = 2:\n","<center><img src = \" https://raw.githubusercontent.com/insaid2018/Term-1/master/Images/brave3.JPG\"/></center>"]}]}